{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Chat-bot.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMR371jdeY1eHJWoCnaZ7tK",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rsradhakrishnan/capstone-projects/blob/main/Chat_bot.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qoMpogiV3QfX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "outputId": "73f8c77f-816d-4c82-aaaf-bf6bbc92c494"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sun Oct 25 17:37:33 2020       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 455.23.05    Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   43C    P8    10W /  70W |      0MiB / 15079MiB |      0%      Default |\n",
            "|                               |                      |                 ERR! |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PvFjaRsnUl4M",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d7f28258-fd06-4a77-8223-e8a45b8945c3"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/gdrive', force_remount=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s-o8TTYWFCtf"
      },
      "source": [
        "import keras\n",
        "import tensorflow as tf\n",
        "import nltk\n",
        "import numpy\n",
        "import sklearn\n",
        "from keras.models import Model\n",
        "from keras.layers.recurrent import LSTM\n",
        "from keras.layers import Dense, Input, Embedding\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from collections import Counter\n",
        "import nltk\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5OrGnKlwVYCZ"
      },
      "source": [
        "RAND_STATE=np.random.seed(42)\n",
        "BATCH_SIZE = 256\n",
        "NUM_EPOCHS = 10\n",
        "GLOVE_EMBEDDING_SIZE = 100\n",
        "HIDDEN_UNITS = 256\n",
        "MAX_INPUT_SEQ_LENGTH = 40\n",
        "MAX_TARGET_SEQ_LENGTH = 40\n",
        "MAX_VOCAB_SIZE = 10000\n",
        "DATA_SET_NAME = 'cornell'\n",
        "DATA_PATH = '/gdrive/My Drive/Industry_Project /movie_lines_cleaned.txt'\n",
        "GLOVE_MODEL = \"/gdrive/My Drive/Industry_Project /glove.twitter.27B.100d.txt\"\n",
        "WHITELIST = 'abcdefghijklmnopqrstuvwxyz1234567890?.,'\n",
        "WEIGHT_FILE_PATH =  DATA_SET_NAME + '-word-glove-weights.h5'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ok8Rq8_aVvuf"
      },
      "source": [
        "def in_white_list(_word):\n",
        "    for char in _word:\n",
        "        if char in WHITELIST:\n",
        "            return True\n",
        "    return False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hBBJOy6ZV_6l"
      },
      "source": [
        "##Glove model\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oQLTIVhMV51H"
      },
      "source": [
        "\n",
        "def load_glove_vector():\n",
        "    _word2embedding = {}\n",
        "    file = open(GLOVE_MODEL, mode='rt', encoding='utf8')\n",
        "    for line in file:\n",
        "        words = line.strip().split()\n",
        "        word = words[0]\n",
        "        #embedding_vectors = np.asarray(words[1:])\n",
        "        embedding_vectors = np.array(words[1:], dtype=np.float32)\n",
        "        _word2embedding[word] = embedding_vectors\n",
        "    file.close()\n",
        "    return _word2embedding"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UukMp76nYEjP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "72c71607-d0d7-41d0-df39-fdb077a19a7e"
      },
      "source": [
        "%%time\n",
        "word2embed = load_glove_vector()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 28 s, sys: 894 ms, total: 28.9 s\n",
            "Wall time: 28.9 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kh240N7RZ43Y",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a1937ce5-86f2-47ee-eed0-ef3757168519"
      },
      "source": [
        "len(word2embed.keys())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1193514"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6DeJMDKoaHEV",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "outputId": "68e3281b-4fb7-4d8a-b9e6-9be475344d38"
      },
      "source": [
        "word2embed.get('train')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 7.8224e-01,  2.1289e-01, -3.7750e-01, -1.0542e+00,  7.1538e-02,\n",
              "        6.5285e-01, -5.0393e-02,  1.4292e-02, -3.3518e-01,  2.0516e-01,\n",
              "       -5.7545e-02,  5.8780e-01, -3.4255e+00, -3.9355e-01, -1.9521e-01,\n",
              "        1.6188e-01,  3.3833e-02, -2.4486e-01, -6.7231e-01, -3.0219e-01,\n",
              "       -1.2911e-01, -1.0401e+00,  3.8679e-01, -5.5795e-01,  5.6450e-01,\n",
              "       -4.3825e-01, -7.3374e-01,  5.0109e-01, -1.3601e-01,  1.4848e+00,\n",
              "        1.1157e-01, -3.2571e-01, -7.0612e-01,  4.5017e-02,  5.7258e-01,\n",
              "       -1.3414e-01, -1.3751e-01,  2.5518e-02,  1.1558e+00, -1.2307e-01,\n",
              "        2.0635e-01,  1.1790e+00, -2.9565e-03, -5.6660e-01,  8.8233e-01,\n",
              "       -2.0549e-01,  5.0556e-01, -2.8319e-01, -3.6040e-01, -4.7111e-01,\n",
              "        3.1520e-01,  3.1712e-01, -1.4541e-01, -3.1394e-01, -6.7899e-01,\n",
              "        8.6945e-02,  5.0997e-01,  5.0802e-01,  1.8457e-01,  1.1322e-01,\n",
              "        7.1866e-01,  1.5100e-01,  2.5895e-01,  3.6208e-01, -6.0227e-01,\n",
              "       -6.3969e-01, -1.3120e-01,  5.0847e-01, -2.6322e-01,  3.8793e-01,\n",
              "        8.6960e-01,  1.0897e-01,  7.9938e-01,  8.4588e-01, -4.0655e-01,\n",
              "        2.7099e-01,  1.8998e-01, -3.7842e-01,  4.9805e-01, -1.3854e+00,\n",
              "        1.5588e+00, -7.4115e-01, -1.4511e-01,  9.7982e-02,  3.0477e-01,\n",
              "        5.6467e-01, -9.7327e-01, -5.5750e-01,  1.1909e+00, -4.1910e-01,\n",
              "        8.2096e-01,  3.2119e-01, -5.3355e-01,  5.4771e-01, -4.3914e-02,\n",
              "        3.0235e-01, -5.6655e-01,  1.1961e-01,  6.2425e-02, -2.9144e-01],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TEvt02lMaeCu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9ac5d8e8-b625-47d6-81e1-bd45eebe8b2b"
      },
      "source": [
        "word2embed.get('train').shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(100,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ulMk8-dDahyO"
      },
      "source": [
        "#word2embed.get('judafbaidb').shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G8G5njybanq2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "5e121155-fdcf-4da5-f470-8a23995919a8"
      },
      "source": [
        "'''\n",
        "assert len(word2embedding.keys())==1193513\n",
        "for key in word2embedding.keys():\n",
        "    try:\n",
        "        assert len(word2embedding[key])==100\n",
        "    except AssertionError:\n",
        "        print (key,len(word2embedding[key]))     \n",
        "\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\nassert len(word2embedding.keys())==1193513\\nfor key in word2embedding.keys():\\n    try:\\n        assert len(word2embedding[key])==100\\n    except AssertionError:\\n        print (key,len(word2embedding[key]))     \\n\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gBrxAfCabQ8W"
      },
      "source": [
        "target_counter = Counter()\n",
        "lines = open(DATA_PATH, 'rt', encoding='utf8').read().split('\\n')\n",
        "input_texts = []\n",
        "target_texts = []\n",
        "prev_words = []"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SrUUrXgCS75n"
      },
      "source": [
        "##Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8A85JklKbf81",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "782df4de-61bf-4b69-afeb-b888004626d3"
      },
      "source": [
        "import nltk\n",
        "nltk.download('punkt')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zb1XMRaQbXW9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "b7131830-7f27-4233-bdea-c812c21687dc"
      },
      "source": [
        "%%time\n",
        "for line in lines:\n",
        "    next_words = [w.lower() for w in nltk.word_tokenize(line)]\n",
        "    if len(next_words) > MAX_TARGET_SEQ_LENGTH:\n",
        "        next_words = next_words[0:MAX_TARGET_SEQ_LENGTH]\n",
        "    if len(prev_words) > 0:\n",
        "        input_texts.append(prev_words)\n",
        "        target_words = next_words[:]\n",
        "        target_words.insert(0, 'start')\n",
        "        target_words.append('end')\n",
        "        for w in target_words:\n",
        "            target_counter[w] += 1\n",
        "        target_texts.append(target_words)\n",
        "    prev_words = next_words"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 48.7 s, sys: 292 ms, total: 49 s\n",
            "Wall time: 49 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dqq7wf5TbbPt",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "c3aab39c-1fe5-4323-8cac-4b065003914f"
      },
      "source": [
        "#after Preprocessing\n",
        "for idx, (input_words, target_words) in enumerate(zip(input_texts, target_texts)):\n",
        "    if idx > 5:\n",
        "        break\n",
        "    print([input_words, target_words])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[['they', 'do', 'not', '!'], ['start', 'they', 'do', 'to', '!', 'end']]\n",
            "[['they', 'do', 'to', '!'], ['start', 'i', 'hope', 'so', '.', 'end']]\n",
            "[['i', 'hope', 'so', '.'], ['start', 'she', 'okay', '?', 'end']]\n",
            "[['she', 'okay', '?'], ['start', 'let', \"'s\", 'go', '.', 'end']]\n",
            "[['let', \"'s\", 'go', '.'], ['start', 'wow', 'end']]\n",
            "[['wow'], ['start', 'okay', '--', 'you', \"'re\", 'gon', 'na', 'need', 'to', 'learn', 'how', 'to', 'lie', '.', 'end']]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RNWhpLCzuORr"
      },
      "source": [
        "## word2index and index2word dictionaries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hCHPIg50cq3I"
      },
      "source": [
        "target_word2idx = dict()\n",
        "'''create a target word to id dictionary called target_word2idx.\n",
        "'''\n",
        "\n",
        "for idx, word in enumerate(target_counter.most_common(MAX_VOCAB_SIZE)):\n",
        "    target_word2idx[word[0]] = idx + 1\n",
        "\n",
        "if 'unk' not in target_word2idx:\n",
        "    target_word2idx['unk'] = 0\n",
        "\n",
        "'''create a target to id dictionary called target_idx2word . '''\n",
        "\n",
        "target_idx2word = dict([(idx, word) for word, idx in target_word2idx.items()])\n",
        "\n",
        "num_decoder_tokens = len(target_idx2word)+1\n",
        "\n",
        "np.save('word-glove-target-word2idx.npy', target_word2idx)\n",
        "np.save('word-glove-target-idx2word.npy', target_idx2word)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OaeYpctKd0p8"
      },
      "source": [
        "#assert len (target_word2idx.keys())==len (target_idx2word.keys())==MAX_VOCAB_SIZE+1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fLrGzPE8wsnS"
      },
      "source": [
        "##creating dictionary of word embedding using loaded glove"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zicVbvh6i2Be"
      },
      "source": [
        "input_texts_word2em = []\n",
        "\n",
        "encoder_max_seq_length = 0\n",
        "decoder_max_seq_length = 0\n",
        "\n",
        "for input_words, target_words in zip(input_texts, target_texts):\n",
        "    encoder_input_wids = []\n",
        "    for w in input_words:\n",
        "        emb = np.zeros(shape=GLOVE_EMBEDDING_SIZE)\n",
        "        if w in word2embed:\n",
        "            emb = word2embed[w]\n",
        "        encoder_input_wids.append(emb)\n",
        "\n",
        "    input_texts_word2em.append(encoder_input_wids)\n",
        "    encoder_max_seq_length = max(len(encoder_input_wids), encoder_max_seq_length)\n",
        "    decoder_max_seq_length = max(len(target_words), decoder_max_seq_length)\n",
        "\n",
        "context = dict()\n",
        "context['num_decoder_tokens'] = num_decoder_tokens\n",
        "context['encoder_max_seq_length'] = encoder_max_seq_length\n",
        "context['decoder_max_seq_length'] = decoder_max_seq_length\n",
        "\n",
        "\n",
        "np.save('word-glove-context.npy', context)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1CqgVkeUjyPl",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ad0fcba6-0cf5-4749-a41e-c5215f9da31a"
      },
      "source": [
        "print(context)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'num_decoder_tokens': 10002, 'encoder_max_seq_length': 40, 'decoder_max_seq_length': 42}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_uYKAXASe1XX"
      },
      "source": [
        "#for input_text,input_text_embed in zip (input_texts,range(len(input_texts_word2em))):\n",
        "#   assert (len(input_text)==len(input_texts_word2em[input_text_embed]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uw28_8aHu8ls"
      },
      "source": [
        "#Generating batches of data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PwMpItndj-Lc"
      },
      "source": [
        "def generate_batch(input_word2em_data, output_text_data):\n",
        "    num_batches = len(input_word2em_data) // BATCH_SIZE\n",
        "    while True:\n",
        "        for batchIdx in range(0, num_batches):\n",
        "            start = batchIdx * BATCH_SIZE\n",
        "            end = (batchIdx + 1) * BATCH_SIZE\n",
        "            encoder_input_data_batch = pad_sequences(input_word2em_data[start:end], encoder_max_seq_length)\n",
        "            decoder_target_data_batch = np.zeros(shape=(BATCH_SIZE, decoder_max_seq_length, num_decoder_tokens))\n",
        "            decoder_input_data_batch = np.zeros(shape=(BATCH_SIZE, decoder_max_seq_length, GLOVE_EMBEDDING_SIZE))\n",
        "            for lineIdx, target_words in enumerate(output_text_data[start:end]):\n",
        "                for idx, w in enumerate(target_words):\n",
        "                    w2idx = target_word2idx['unknown']  #by default unknown\n",
        "                    if w in target_word2idx:\n",
        "                        w2idx = target_word2idx[w]\n",
        "                    if w in word2embed:\n",
        "                        decoder_input_data_batch[lineIdx, idx, :] = word2embed[w]\n",
        "                    if idx > 0:\n",
        "                        decoder_target_data_batch[lineIdx, idx - 1, w2idx] = 1\n",
        "            yield [encoder_input_data_batch, decoder_input_data_batch], decoder_target_data_batch"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tDLKCftHgQhq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 103
        },
        "outputId": "fd7062c4-5138-4205-97e2-ad1a631cf9e3"
      },
      "source": [
        "'''\n",
        "Xtrain, Xtest, Ytrain, Ytest = train_test_split(input_texts_word2em, target_texts, test_size=0.2, random_state=42)\n",
        "train_gen = generate_batch(Xtrain, Ytrain)\n",
        "for i,j in train_gen:\n",
        "    assert i[0].shape == (BATCH_SIZE,context['encoder_max_seq_length'],GLOVE_EMBEDDING_SIZE)\n",
        "    assert i[1].shape == (BATCH_SIZE,context['decoder_max_seq_length'],GLOVE_EMBEDDING_SIZE)\n",
        "    assert j.shape == (BATCH_SIZE,context['decoder_max_seq_length'],context['num_decoder_tokens'])\n",
        "\n",
        "print ('Test Case 4 Passes!')\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"\\nXtrain, Xtest, Ytrain, Ytest = train_test_split(input_texts_word2em, target_texts, test_size=0.2, random_state=42)\\ntrain_gen = generate_batch(Xtrain, Ytrain)\\nfor i,j in train_gen:\\n    assert i[0].shape == (BATCH_SIZE,context['encoder_max_seq_length'],GLOVE_EMBEDDING_SIZE)\\n    assert i[1].shape == (BATCH_SIZE,context['decoder_max_seq_length'],GLOVE_EMBEDDING_SIZE)\\n    assert j.shape == (BATCH_SIZE,context['decoder_max_seq_length'],context['num_decoder_tokens'])\\n\\nprint ('Test Case 4 Passes!')\\n\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "88WwSYQOuwXz"
      },
      "source": [
        "#Splitting in to Train and Validation data "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F-rUVv1JghIe"
      },
      "source": [
        "Xtrain, Xtest, Ytrain, Ytest = train_test_split(input_texts_word2em, target_texts, test_size=0.2, random_state=42)\n",
        "\n",
        "#execution and updation of wt in batches\n",
        "train_gen = generate_batch(Xtrain, Ytrain)\n",
        "test_gen = generate_batch(Xtest, Ytest)\n",
        "\n",
        "train_num_batches = len(Xtrain) // BATCH_SIZE\n",
        "test_num_batches = len(Xtest) // BATCH_SIZE"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0J8kklRuufsT"
      },
      "source": [
        "#model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RmVuXb0JbVCo",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7aa9b724-22cf-4783-d072-cf5473674ace"
      },
      "source": [
        "#Encoder layers \n",
        "encoder_inputs = Input(shape=(None, GLOVE_EMBEDDING_SIZE), name='encoder_inputs')\n",
        "encoder_lstm = LSTM(units=HIDDEN_UNITS, return_state=True, name='encoder_lstm', )\n",
        "encoder_outputs, encoder_state_h, encoder_state_c = encoder_lstm(encoder_inputs)\n",
        "encoder_states = [encoder_state_h, encoder_state_c]\n",
        "\n",
        "#Decoder layers \n",
        "decoder_inputs = Input(shape=(None, GLOVE_EMBEDDING_SIZE), name='decoder_inputs')\n",
        "decoder_lstm = LSTM(units=HIDDEN_UNITS, return_state=True, return_sequences=True, name='decoder_lstm')\n",
        "decoder_outputs, decoder_state_h, decoder_state_c = decoder_lstm(decoder_inputs,\n",
        "                                                                 initial_state=encoder_states)\n",
        "decoder_dense = Dense(units=num_decoder_tokens, activation='softmax', name='decoder_dense')\n",
        "decoder_outputs = decoder_dense(decoder_outputs)\n",
        "#model \n",
        "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
        "model.compile(loss='categorical_crossentropy', optimizer='rmsprop',metrics=['accuracy'])\n",
        "json = model.to_json()\n",
        "open('word-architecture.json', 'w').write(json)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3048"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fe2zuRGFbuj5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 417
        },
        "outputId": "788e2423-3312-4dd7-87d2-f951833b93ab"
      },
      "source": [
        "from keras.utils import plot_model\n",
        "plot_model(model, to_file='model.png')\n",
        "from IPython.display import Image\n",
        "Image(filename='model.png',height=400,width=400)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {
            "tags": [],
            "image/png": {
              "width": 400,
              "height": 400
            }
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "krMIGDfgt8Ic"
      },
      "source": [
        "checkpoint = ModelCheckpoint(filepath=WEIGHT_FILE_PATH, save_best_only=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8fCOzDeZX_p_"
      },
      "source": [
        "## Training chatbot model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oRcIRVz2bdOr",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "outputId": "a5c0eb50-46a5-467b-c3ba-052ff2177013"
      },
      "source": [
        "model.fit(x=train_gen, steps_per_epoch=train_num_batches,\n",
        "          epochs=NUM_EPOCHS,\n",
        "          verbose=1, validation_data=test_gen, validation_steps=test_num_batches, callbacks=[checkpoint])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "951/951 [==============================] - 526s 553ms/step - loss: 1.5301 - accuracy: 0.0719 - val_loss: 1.4120 - val_accuracy: 0.0845\n",
            "Epoch 2/5\n",
            "951/951 [==============================] - 531s 559ms/step - loss: 1.3666 - accuracy: 0.0882 - val_loss: 1.3514 - val_accuracy: 0.0908\n",
            "Epoch 3/5\n",
            "951/951 [==============================] - 524s 551ms/step - loss: 1.3234 - accuracy: 0.0921 - val_loss: 1.3254 - val_accuracy: 0.0935\n",
            "Epoch 4/5\n",
            "951/951 [==============================] - 511s 538ms/step - loss: 1.2999 - accuracy: 0.0943 - val_loss: 1.3117 - val_accuracy: 0.0948\n",
            "Epoch 5/5\n",
            "951/951 [==============================] - 515s 542ms/step - loss: 1.2846 - accuracy: 0.0958 - val_loss: 1.3031 - val_accuracy: 0.0958\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f556bf99da0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-aoEMo7qbjAS"
      },
      "source": [
        "\n",
        "model.save_weights(WEIGHT_FILE_PATH)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1CpeqBGcgnGs"
      },
      "source": [
        "model.save('partly_trained.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "quapR00w2bfA"
      },
      "source": [
        "##loading half trained model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7T6WPUV1gBDW",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "bdc03f60-e831-463a-a763-232c4f409137"
      },
      "source": [
        "from keras import backend as K\n",
        "from keras.models import load_model\n",
        "loaded_model =  keras.models.load_model('partly_trained.h5')\n",
        "print(\"Learning rate before first fit:\", loaded_model.optimizer.learning_rate.numpy())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Learning rate before first fit: 0.01\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Io53a81J-EJ0"
      },
      "source": [
        "K.set_value(loaded_model.optimizer.learning_rate, 0.001)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KJI2oyEe-0zM",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "cc909743-c397-402c-c3d4-cac8db3fc613"
      },
      "source": [
        "print(\"Learning rate after first fit:\", loaded_model.optimizer.learning_rate.numpy())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Learning rate after first fit: 0.001\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_5QTVHKpgRev",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "44222226-bfba-4256-cd16-7c3ff62b2987"
      },
      "source": [
        "%%time\n",
        "history = loaded_model.fit(x=train_gen, steps_per_epoch=train_num_batches,\n",
        "          epochs=10,\n",
        "          verbose=1, validation_data=test_gen, validation_steps=test_num_batches, callbacks=[checkpoint])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "1260/1260 [==============================] - ETA: 0s - loss: 1.2318 - accuracy: 0.1043"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2g3uUoG73UY_"
      },
      "source": [
        "##the model was trained for 30 epocs with two learning rates, i.e 0.1 and 0.01"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4J8dLorLq592"
      },
      "source": [
        "loaded_model.save('trained_model.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JTB4K7wost2o"
      },
      "source": [
        "#loaded_model.save_weights(WEIGHT_FILE_PATH)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s5IS0e0ApbPP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 309
        },
        "outputId": "ed230e10-7c38-4c88-d82e-4c1689ad1b65"
      },
      "source": [
        "!pip install numpy==1.16.1\n",
        "import numpy as np\n",
        "#REF : https://stackoverflow.com/questions/55890813/how-to-fix-object-arrays-cannot-be-loaded-when-allow-pickle-false-for-imdb-loa"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting numpy==1.16.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f5/bf/4981bcbee43934f0adb8f764a1e70ab0ee5a448f6505bd04a87a2fda2a8b/numpy-1.16.1-cp36-cp36m-manylinux1_x86_64.whl (17.3MB)\n",
            "\u001b[K     |████████████████████████████████| 17.3MB 206kB/s \n",
            "\u001b[31mERROR: umap-learn 0.4.6 has requirement numpy>=1.17, but you'll have numpy 1.16.1 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: albumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: numpy\n",
            "  Found existing installation: numpy 1.18.5\n",
            "    Uninstalling numpy-1.18.5:\n",
            "      Successfully uninstalled numpy-1.18.5\n",
            "Successfully installed numpy-1.16.1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oaZ3HOok2hlC"
      },
      "source": [
        "##prediction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mn2Aq3iZnEVq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "8acb04cc-7895-41c1-fc95-cb2938b977b1"
      },
      "source": [
        "from keras.models import Model\n",
        "from keras.layers import Input, LSTM, Dense\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "import numpy as np\n",
        "import nltk\n",
        "import os\n",
        "import sys\n",
        "import zipfile\n",
        "import urllib\n",
        "from keras.models import model_from_json\n",
        "\n",
        "HIDDEN_UNITS = 256\n",
        "WHITELIST = 'abcdefghijklmnopqrstuvwxyz1234567890?.,'\n",
        "GLOVE_EMBEDDING_SIZE = 100\n",
        "DATA_SET_NAME = 'cornell'\n",
        "\n",
        "class CornellWordGloveChatBot(object):\n",
        "    model = None\n",
        "    encoder_model = None\n",
        "    decoder_model = None\n",
        "    target_word2idx = None\n",
        "    target_idx2word = None\n",
        "    max_decoder_seq_length = None\n",
        "    max_encoder_seq_length = None\n",
        "    num_decoder_tokens = None\n",
        "    word2em = None\n",
        "\n",
        "    def __init__(self):\n",
        "        self.word2em = word2embed\n",
        "        #print(len(self.word2em))\n",
        "        #print(self.word2em['start'])\n",
        "\n",
        "        self.target_word2idx = np.load('word-glove-target-word2idx.npy').item()\n",
        "        self.target_idx2word = np.load('word-glove-target-idx2word.npy').item()\n",
        "        context = np.load('word-glove-context.npy').item()\n",
        "        self.max_encoder_seq_length = context['encoder_max_seq_length']\n",
        "        self.max_decoder_seq_length = context['decoder_max_seq_length']\n",
        "        self.num_decoder_tokens = context['num_decoder_tokens']\n",
        "\n",
        "        encoder_inputs = Input(shape=(None, GLOVE_EMBEDDING_SIZE), name='encoder_inputs')\n",
        "        encoder_lstm = LSTM(units=HIDDEN_UNITS, return_state=True, name=\"encoder_lstm\")\n",
        "        encoder_outputs, encoder_state_h, encoder_state_c = encoder_lstm(encoder_inputs)\n",
        "        encoder_states = [encoder_state_h, encoder_state_c]\n",
        "\n",
        "        decoder_inputs = Input(shape=(None, GLOVE_EMBEDDING_SIZE), name='decoder_inputs')\n",
        "        decoder_lstm = LSTM(units=HIDDEN_UNITS, return_sequences=True, return_state=True, name='decoder_lstm')\n",
        "        decoder_outputs, _, _ = decoder_lstm(decoder_inputs, initial_state=encoder_states)\n",
        "        decoder_dense = Dense(self.num_decoder_tokens, activation='softmax', name='decoder_dense')\n",
        "        decoder_outputs = decoder_dense(decoder_outputs)\n",
        "\n",
        "        self.model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
        "\n",
        "        model_json = open('/content/word-architecture.json', 'r').read()\n",
        "        self.model = model_from_json(model_json)\n",
        "        self.model.load_weights('cornell-word-glove-weights.h5')\n",
        "        self.model.compile(optimizer='rmsprop', loss='categorical_crossentropy')\n",
        "\n",
        "        self.encoder_model = Model(encoder_inputs, encoder_states)\n",
        "\n",
        "        decoder_state_inputs = [Input(shape=(HIDDEN_UNITS,)), Input(shape=(HIDDEN_UNITS,))]\n",
        "        decoder_outputs, state_h, state_c = decoder_lstm(decoder_inputs, initial_state=decoder_state_inputs)\n",
        "        decoder_states = [state_h, state_c]\n",
        "        decoder_outputs = decoder_dense(decoder_outputs)\n",
        "        self.decoder_model = Model([decoder_inputs] + decoder_state_inputs, [decoder_outputs] + decoder_states)\n",
        "\n",
        "    def reply(self, input_text):\n",
        "        input_seq = []\n",
        "        input_emb = []\n",
        "        for word in nltk.word_tokenize(input_text.lower()):\n",
        "            if not in_white_list(word):\n",
        "                continue\n",
        "            emb = np.zeros(shape=GLOVE_EMBEDDING_SIZE)\n",
        "            if word in self.word2em:\n",
        "                emb = self.word2em[word]\n",
        "            input_emb.append(emb)\n",
        "        input_seq.append(input_emb)\n",
        "        input_seq = pad_sequences(input_seq, self.max_encoder_seq_length)\n",
        "        states_value = self.encoder_model.predict(input_seq)\n",
        "        target_seq = np.zeros((1, 1, GLOVE_EMBEDDING_SIZE))\n",
        "        target_seq[0, 0, :] = self.word2em['start']\n",
        "        target_text = ''\n",
        "        target_text_len = 0\n",
        "        terminated = False\n",
        "        while not terminated:\n",
        "            output_tokens, h, c = self.decoder_model.predict([target_seq] + states_value)\n",
        "            [[0.43,1.32,0],[0,0,1]]\n",
        "            sample_token_idx = np.argmax(output_tokens[0, -1, :])\n",
        "            sample_word = self.target_idx2word[sample_token_idx]\n",
        "            target_text_len += 1\n",
        "\n",
        "            if sample_word != 'start' and sample_word != 'end':\n",
        "                target_text += ' ' + sample_word\n",
        "\n",
        "            if sample_word == 'end' or target_text_len >= self.max_decoder_seq_length:\n",
        "                terminated = True\n",
        "\n",
        "            target_seq = np.zeros((1, 1, GLOVE_EMBEDDING_SIZE))\n",
        "            if sample_word in self.word2em:\n",
        "                target_seq[0, 0, :] = self.word2em[sample_word]\n",
        "\n",
        "            states_value = [h, c]\n",
        "        return target_text.strip()\n",
        "\n",
        "    def test_run(self):\n",
        "        print(self.reply('good morning'))\n",
        "        #print(self.reply('How are you doing?'))\n",
        "        #print(self.reply('Have you heard the news?'))\n",
        "\n",
        "\n",
        "def main():\n",
        "    model = CornellWordGloveChatBot()\n",
        "    model.test_run()\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "appearance appearance reagan species pipeline housekeeper foundation housekeeper foundation foundation housekeeper foundation fuck canceled excalibur excalibur starks treadstone machine section shades apiece touching problems verge touching cone sniffing sniffing bully exciting ammunition sniffing sniffing sniffing sniffing pet sniffing sniffing pet sniffing sniffing\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3A7qVdecHaWz"
      },
      "source": [
        "With very less training model is able to predict this, clearly shows that training has to be for longer "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DiqHXgYWGYZl"
      },
      "source": [
        "##Further work can be done by to increase the accuracy and lower the loss by introducing the attention mechanism\n",
        "#ref: https://towardsdatascience.com/intuitive-understanding-of-attention-mechanism-in-deep-learning-6c9482aecf4f"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}